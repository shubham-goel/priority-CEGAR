\documentclass{sig-alternate-05-2015}[9pt]

	\usepackage{times}
	\usepackage{amssymb}
	%\usepackage{amsmath}
	\usepackage{dsfont}
	\usepackage{xspace}
	\usepackage{graphicx}
	\usepackage{mathabx}
	\let\proof\relax 
	\let\endproof\relax
	\usepackage{amsthm}

	\usepackage{multirow}

	\usepackage{algpseudocode}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}


	%\renewcommand{\baselinestretch}{1.15}

	\newcommand{\zug}[1]{\langle #1  \rangle}
	\newcommand{\set}[1]{\{ #1  \}}
	\newcommand{\stam}[1]{}
	\newcommand{\bft}{\mbox{\em \bf true}}
	\newcommand{\bff}{\mbox{\em \bf false}}
	%\newcommand{\track}[1]{{\textcolor{red}{#1}}}



	\newcommand{\A}{{\cal A}}
	\newcommand{\B}{{\cal B}}
	\newcommand{\C}{{\cal C}}
	\newcommand{\D}{{\cal D}}
	\newcommand{\G}{{\cal G}}
	\renewcommand{\L}{{\cal L}}
	\newcommand{\N}{{\cal N}}
	\newcommand{\M}{{\cal M}}
	\newcommand{\T}{{\cal T}}

	\newcommand{\Nat}{\mathds{N}}
	\newcommand{\Rat}{\mathds{Q}}
	\newcommand{\Qpos}{\Rat^{\geq 0}}
	\newcommand{\Real}{\mathds{R}}
	\newcommand{\Whole}{\mathds{Z}}

	\newcommand{\Prot}{\mbox{\sc Prot}}


	\newcommand{\osigma}{\overline{\sigma}}

	\newcommand{\used}{\eta}
	\newcommand{\usedb}{\kappa}

	\newcommand{\PO}{Player~$1$\xspace}
	\newcommand{\PT}{Player~$2$\xspace}
	\newcommand{\PR}{Player~$3$\xspace}
	\newcommand{\PF}{Player~$4$\xspace}

	\newcommand{\FP}{\text{FP}}
	\newcommand{\SP}{\text{SP}}
	\newcommand{\Prc}{\text{Prc}}



	\newcommand{\ff}{\texttt{f\!f}\xspace}
	\renewcommand{\tt}{\texttt{t\!t}\xspace}


	\newcommand{\start}{\mbox{start}\xspace}
	\newcommand{\eend}{\mbox{end}\xspace}




	\newtheorem{theorem}{Theorem}[section]
	\newtheorem{proposition}[theorem]{Proposition}
	\newtheorem{property}[theorem]{Property}
	\newtheorem{corollary}[theorem]{Corollary}
	\newtheorem{observation}[theorem]{Observation}
	\newtheorem{lemma}[theorem]{Lemma}
	\newtheorem{claim}[theorem]{Claim}
	\newtheorem{fact}[theorem]{Fact}
	\newtheorem{definition}{Definition}[section]
	\newtheorem{algorithm}{Algorithm}[section]
	\theoremstyle{definition}
	\newtheorem{example}{Example}[section]
	\newtheorem{rmrk}[theorem]{Remark}
	%\newtheorem{exmpl}[theorem]{Example}
	%\newenvironment{example}{\begin{exmpl}\rm}{\hspace{\stretch{1}\hfill\qed}\end{exmpl}}

	\newenvironment{remark}{\begin{rmrk}\rm}{\hspace{\stretch{1}}\end{rmrk}}

	\def\eod{\vrule height 6pt width 5pt depth 0pt}
	\renewenvironment{proof}{\noindent {\bf Proof:} \hspace{.677em}} {\hspace*{\fill}{\eod}}



	\begin{document}
	\setcopyright{acmcopyright}

	% DOI
	\doi{10.475/123_4}

	% ISBN
	\isbn{123-4567-24-567/08/06}

	%Conference
	\conferenceinfo{EMSOFT}{October 2--7, 2016, Pittsburgh, PA, USA}

	\acmPrice{\$15.00}

	%
	% --- Author Metadata here ---
	\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
	%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
	%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
	% --- End of Author Metadata ---

	\title{Synthesizing Time-Triggered Schedules for Switched Networks with Faulty Links}
	\author{Authors' names deliberately omitted for blind review}

	%\author{
	%\alignauthor
	%Guy Avni\\
	%       \affaddr{IST Austria}\\
	% %      \affaddr{Wallamaloo, New Zealand}\\
	%       \email{guy.avni@ist.ac.at}
	%\alignauthor
	%Shibashis Guha\\
	%       \affaddr{Hebrew University}\\
	%   %    \affaddr{Wallamaloo, New Zealand}\\
	%       \email{shibashis@cse.iitd.ac.in}
	%\alignauthor
	%Guillermo Rodriguez-Navas\\
	%       \affaddr{MÃ¤lardalen University}\\
	%     %  \affaddr{Wallamaloo, New Zealand}\\
	%       \email{guillermo.rodriguez-navas@mdh.se}
	%}



	\maketitle


\section{Evaluation}
	\label{sec:eval}
	We have implemented Weighted Model Counting, Iterative approach and the Monte-Carlo Approach for scoring forwarding schemes, which are described in Section~\ref{sec:counting} and~\ref{sec:monte-carlo}. Our implementations are in Python and rely on counting tools - both unweighted (sharp-Sat \cite{sharpSat}, cryptominsat \cite{cryptominsat}) and weighted (WeightMC \cite{WeightMC}). We ran our experiments on a personal computer, Intel Core i3 quad core 3.40 GHz processor, with 8 GB memory.

	\noindent{\bf Network and {\em forwarding scheme} generation}
		We evaluate the algorithm on networks that were generated randomly by the Python library Networkx
		 \cite{HSS08}.
		The networks are generated in the following manner.
		We fix the number of vertices, edges, and messages.
		We generate a random directed graph.
		%We consider relatively dense graphs, where % This may not be considered dense.
		%The number of edges ranges from $1.2$ to $1.5$ times the number of vertices.
		We consider relatively dense graphs, where the number of edges are approximately 2 times the number of vertices.
		Once we have a graph, we randomly select a source and a target for each message,
		while guaranteeing that these are different nodes.
		We refer to a graph and messages with the source and the target vertices, 
		as the {\em setting}.
		For each setting, the {\em forwarding scheme} is generated deterministically.

		We find the edge priorities for each message and message priorities for each vertex. We note that the problem of finding ``good'' priorities is a crucial component of the protocol. It is a challenging problem both theoretically and practically, and it is out of the scope of this paper. We now describe the edge priority-finding algorithm used. We start with a simple approach.

		Consider a message $m \in \M$. Recall that $s(m)$ and $t(m)$ denote the source vertex
		and the target vertex of message $m$, respectively. For finding the edge priorities at different vertices, we find first and second paths for the message $m$. For all edges outgoing from vertex $v$, an edge in the first path will have higher priority than one in the second path. If $v$ doesn't lie on any of the first of second paths, $m$ cannot be forwarded from $v$.
		The first path is the shortest path between $s(m)$ and $t(m)$.
		To find the second path, we remove the edges that the first path traverses.
		For each vertex $v$ on the first path,
		we set the second path from $v$ to be the shortest path from $v$ to $t(m)$ in the new graph, if it exists. 
		The problem with this simple approach is that the second paths are of similar lengths for the different messages, making it hard to calculate the {\em Score}. Thus, we improve the approach by, intuitively, having messages avoid heavily loaded edges when selecting the two paths. Technically, the graph is now weighted. The weight of an edge refers to the number of times it appears in a first or second path. We construct the weights in the graph incrementally. The weights start from $0$. We order the messages arbitrarily and choose them one by one. When a message is chosen, it selects its first and second paths similarly to the above (only running Dijkstra's algorithm rather than a BFS for finding shortest paths). The weight of every edge on the first and second path is incremented by $1$.

		Next, we decide message priorities for each vertex arbitrarily.
		% Upon implementing different heuristics for deciding message priorities, we notice that different heuristics result in different {\em Scores}. For the purpose of evaluation, we use the {\em longest path first} heuristic where a message with a longer first path has higher priority than those with shorter paths. 
		As a last step before finding the {\em Score}, we need to decide the {\em forwarding algorithm}. Though both {\em Hot-Potato} and {\em Fallback} approaches have been implemented, all results displayed have been obtained using the {\em Hot-Potato} approach, which is described in Example~\ref{ex:hot-potato}. 

	\noindent{\bf Execution time measurements}
		We elaborate on the different approaches for scoring the {\em forwarding scheme} generated above and show corresponding run times obtained using settings ranging from 4 nodes to 45 nodes. Each setting contains a relatively dense graph, with number of edges being 2 times the number of nodes, the timeout and number of messages equalling the number of nodes. Both the fault probabilities $pr_{\text{crashes}}$ and $pr_{\text{omission}}$ are set to $0.01$ for thepurposes of this evaluation. All results have been averaged over 3-5 runs. Each program times out after 1 hour, returning ``Timeout'' if it has not terminated by then.

		{\bf WMC}: 
			For WMC in Section~\ref{sec:WMC}, we reduce the SAT program generated in Theorem~\ref{thm:fault seq} to literal-weighted WMC using Theorem~\ref{thm:literal WMC}, and further to an Unweighted Model Counting (UMC, for short) formula \varphi, as described in \cite{Weightd to Unweighted}. Though the reduction in Theorem~\ref{thm:literal WMC} leads to the exact computation of the {\em Score} theoretically, while implementing, we must truncate the weights $w$ to a particular bit {\em precision} because the size of the reduced formula increases with the size of the binary representation of $w$. For similar reasons, we also need to truncate the $1/(2-w)$ term in the Proof of Theorem~\ref{thm:literal WMC} to {\em precision} bits. These truncations lead to errors in the {\em Score}, the magnitude depending on both - the {\em precision} and the {\em Setting}.
			Recall that $SAT(\varphi)$ is the set of satisfying assignments to \varphi. Let the size of $SAT(\varphi)$ be $\#\varphi$. The {\em Score} equals $\#\varphi$, after normalization. $\#\varphi$ can be calculated using exact counting tools like {\em sharp-Sat} \cite{sharpSAT} and approximate counting tools like {\em cryptominsat} \cite{cryptominsat} and {\em approxMC} \cite{approxMC}. One would expect approximation tools to perform much better than exact counting tools. However, sharp-Sat performs much better than cryptominsat and approxMC, which didn't terminate even for small settings with 5 nodes. The authors of \cite{approxMC} also confirmed this observation in \cite{this}%http://www.cs.rice.edu/~kgm2/Papers/ijcai15.pdf
			. Note that the performance of the WMC method is very dependent upon the SAT counter that is used for calculating $\#\varphi$. Hence, the WMC method cannot be used for large problem sizes because of limitations of sharp-SAT. Future improvements in SAT counting tools will improve the performance of WMC.

			Figure 1 shows the processing and counting times for WMC with a precision of 10 bits. All counting has been done using sharp-SAT.

			{\bf Figure 1 comes here}

		{\bf Iterative Approach}: 
			We breifly explain the implementation of the $CalcBadProb$ method described in Section~\ref{sec:Iterative}. First, it generates a SAT formula using Theorem~\ref{thm:fault seq} and Lemma~\ref{lem:calc-prob}, and reduces it to literal-weighted WMC using Theorem~\ref{thm:literal WMC}. The weight of this literal-weighted WMC (after normalization) is to be returned, and is approximated using \cite{WeightGen}. By Lemma~\ref{lem:tilt} and \cite{WeightGen}, we know that the approximation obtained is reasonable.

			In an alternate implementation of the {\em CalcBadProb} method, we generate an SMT formula $\varphi$ using Theorem~\ref{thm:fault seq} and add the SMT constraint that exactly k crashes occur. We use Z3 \cite{Z3} for solving this formula. Then, we iteratively find a solution $\sigma$ to $\varphi$, add $\neg \sigma$ back to $\varphi$ as a constraint and repeat this process until $\varphi$ is UNSAT. We return the sum of probabilities of the solutions $\sigma$ obtained in the iterations. This is a very naive counting method. We try optimizing it using an optimization described in the previous paper, where it worked very well.

			Figure 2 shows the processing and counting times for various implementations of the Iterative approach for different values of k. We use an uncertainity of $0.01$. Note that this approach focusses only on crash faults and assumes $pr_{omission}=0$.

			{\bf Figure 2 comes here}

		{\bf Monte-Carlo}: 
			The Monte-Carlo approach, which is described in Section~\ref{sec:monte-carlo} was also implemented in Python using randomization functions from the numpy \cite{numpy} library. We used the Hoeffding's Inequality \cite{hoeffding} to calculate the number of iterations needed to acheive the desired error and confidence levels. We also tried to improve the run time by using multiprocessing. We evaluated the Monte Carlo approach using an error $\epsilon=0.01$, and a confidence of $\delta=0.99$. We used 4 threads for the multiprocessing variant of Monte-Carlo approach. We choose this number after comparing the run times of the threaded approach  with different number of threads. The run times obtained for the threaded and linear programs are shown in Figure 3.

			{\bf Figure 3 comes here}

	\noindent{\bf Observations}
	Upon comparing Figures 1, 2 and 3, it seems that the Iterative approach scales better than WMC. However, the probability bounds provided by the Iterative approach are very loose for large Networks. We see that the WMC approach works very well for small settings consisting of upto 7 nodes. For settings larger than this, the Monte-Carlo approach works the best. Figure 4 combines the results in Figures 1-3, and gives a clear idea of the relative run times of the WMC, Iterative approaches and the Monte-Carlo approach. 

% --------------------Parse Pointer--------------------------

\end{document}